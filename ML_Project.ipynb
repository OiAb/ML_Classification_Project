{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYMYyEZ0rt5s"
      },
      "source": [
        "# **Rapport sur le sujet : Prédiction des tentatives suicidaires**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cMe1a46r-AB"
      },
      "source": [
        "Le sujet de notre étude vise à analyser un jeu de données issu d'un sondage effectué sur le subreddit Foreveralone. Il répertorie de nombreuses caractéristiques des personnes dont une indiquant si la personne a déjà effectué une tentative de suicide ou non. Notre but est d'analyser ce dataset et d'utiliser différentes méthodes de Machine Learning pour prédire les profils des personnes qui sont celles ayant le plus tendance à tenter de mettre fin à leurs jours. Sur ce, nous sommes essentiellement amenés à fournir un prédicteur h qui pour un individu donné pourrait prédire son appartenance à une des classes suivantes : 1 : tentative suicidaire, 2 : cas contraire, en se basant sur des exemples de paires entrée-sortie.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCDtMhB9seBz"
      },
      "source": [
        "# **Choix du sujet**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyObOjvAs3tG"
      },
      "source": [
        "On trouve parmi les raisons qui nous ont encouragés à choisir notre sujet : \n",
        "\n",
        "- Sujet très peu traité en Machine Learning (on traite souvent le taux de suicide) \n",
        "- Curiosité de savoir quels sont les facteurs qui poussent un individu à tenter de se suicider \n",
        "- Suite à notre étude, on pourra sensibiliser les individus sur les raisons derrière un suicide"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2Lrc-kBum3Y"
      },
      "source": [
        "# **Identification des tâches à réaliser**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lb_lH8PQuzSe"
      },
      "source": [
        "- Analyser le dataset \n",
        "- Nettoyer le dataset \n",
        "- Choisir nos features \n",
        "- Définir les modèles \n",
        "- Implémenter les algorithmes \n",
        "- Evaluer la performance de notre étude \n",
        "- Réaliser un prédicteur"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ww_e7vv3vDJl"
      },
      "source": [
        "Premièrement, nous allons importer les bibliothèques dont nous aurons besoin"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nkj0cAjPUm8Y"
      },
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from IPython.display import display\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0j6mLL1CxoJ3"
      },
      "source": [
        "Nous allons lire les données à partir du fichier foreveralone.csv que nous avons déposé dans le dossier content."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "mAxyY25jAfHG"
      },
      "source": [
        "data_suicide = pd.read_csv('/content/foreveralone.csv',encoding = \"ISO-8859-1\")\n",
        "data_suicide.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wndlXHDklgyP"
      },
      "source": [
        "On retire les colonnes du dataset qui ne sont pas pertinentes pour la prédiction ou trop difficile à traiter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LshlFXuD7UvO"
      },
      "source": [
        "# **L'analyse de données**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPVcGYQu7d2z"
      },
      "source": [
        "Dans cette partie, on essaie d'analyser et visuliser nos données et puis diviser notre sujet ou une substance complexe en parties plus petites afin d'en acquérir une meilleure compréhension et interprétation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "WvxoA1SeH0E0"
      },
      "source": [
        "data_suicide = data_suicide.drop(['time', 'pay_for_sex', 'prostitution_legal', 'job_title'], axis=1)\n",
        "data_suicide.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "GfWLqgV2oGBE"
      },
      "source": [
        "data_suicide.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "pRcpNtfbHh1g"
      },
      "source": [
        "data_suicide.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8NKOEIEl-if"
      },
      "source": [
        "On cherche si si notre dataset comporte des valeurs nulles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "seCa9s6eITBh"
      },
      "source": [
        "data_suicide.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbcjOSh8mXnk"
      },
      "source": [
        "La façon dont a été généré ce dataset nous a obligé à éliminer certaines réponses non pertinentes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "S_OQn4vnN93b"
      },
      "source": [
        "i1 = data_suicide[(data_suicide.race == 'First two answers. Gender is androgyne, not male; sexuality is asexual, not bi.')].index\n",
        "i2 = data_suicide[(data_suicide.race == 'helicopterkin') ].index\n",
        "data_suicide = data_suicide.drop(i1)\n",
        "data_suicide = data_suicide.drop(i2)\n",
        "data_suicide.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UO2BXCMWmcVq"
      },
      "source": [
        "On change le \"gender\" en valeurs binaires, et les deux autres valeurs de \"Transgender Male\" et \"Transgender Female\" sont changées pour correspondre à l'un des deux.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "aMlqAACDpvhM"
      },
      "source": [
        "data_suicide['gender'] = data_suicide['gender'].replace({'Male':1,'Female':0, 'Transgender male':1, 'Transgender female':0})\n",
        "data_suicide.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3BbqELbmk4_"
      },
      "source": [
        "On procède de même avec \"sexuality\" en séparant \"Straight\" du reste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "6e-dOkwFqEFp"
      },
      "source": [
        "data_suicide['sexuallity'] = data_suicide['sexuallity'].replace({'Straight':1,'Bisexual':0, 'Gay/Lesbian':0})\n",
        "data_suicide.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CvoWutrmoSM"
      },
      "source": [
        "Pour le \"income\", chaque réponse possible est devenue une colonne à part entière. Chaque ligne ne présente donc qu'un unique 1 parmi ces colonnes. On renomme également ces colonnes pour qu'elles soient plus parlantes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "nkQA2Gdwu5N8"
      },
      "source": [
        "A = pd.get_dummies(data_suicide['income'])\n",
        "data_suicide = data_suicide.drop('income', axis=1)\n",
        "data_suicide = pd.concat([data_suicide, A], axis=1)\n",
        "data_suicide=data_suicide.rename(columns={'$0': 'income $0',\n",
        "       '$1 to $10,000': 'income $1 to $10,000', '$10,000 to $19,999': 'income $10,000 to $19,999', '$100,000 to $124,999': 'income $100,000 to $124,999',\n",
        "       '$125,000 to $149,999': 'income $125,000 to $149,999', '$150,000 to $174,999': 'income $150,000 to $174,999', '$174,999 to $199,999': 'income $174,999 to $199,999',\n",
        "       '$20,000 to $29,999': 'income $20,000 to $29,999', '$200,000 or more': 'income $200,000 or more', '$30,000 to $39,999': 'income $30,000 to $39,999',\n",
        "       '$40,000 to $49,999': 'income $40,000 to $49,999', '$50,000 to $74,999': 'income $50,000 to $74,999', '$75,000 to $99,999': 'income $75,000 to $99,999'})\n",
        "data_suicide.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO5L9lYcmq44"
      },
      "source": [
        "La colonne \"race\" contenait de nombreuses valeurs différentes et parfois incohérentes. Il a fallu en regrouper plusieurs en une seule puis les convertir en colonnes par la suite."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "etAb7dh0HsvJ"
      },
      "source": [
        "data_suicide['race'].value_counts()\n",
        "data_suicide['race'] = data_suicide['race'].replace({'half Arab':'Arab','North African':'Arab', \n",
        "                                                 'White and Native American':'White non-Hispanic', 'Native american':'White non-Hispanic',\n",
        "                                                 'European':'White non-Hispanic','caucasian':'White non-Hispanic',\n",
        "                                                 'Turkish':'Asian','Indian':'Asian','Middle Eastern':'Asian','Pakistani':'Asian', 'indian':'Asian',\n",
        "                                                  'Mixed race':'Mixed','mixed':'Mixed','Multi':'Mixed','Mixed white/asian':'Mixed', 'Half Asian half white':'Mixed','Native American mix':'Mixed','white and asian':'Mixed'\n",
        "                                                })\n",
        "data_suicide['race'].value_counts()\n",
        "\n",
        "B = pd.get_dummies(data_suicide['race'])\n",
        "data_suicide = data_suicide.drop('race', axis=1)\n",
        "data_suicide = pd.concat([data_suicide, B], axis=1)\n",
        "data_suicide.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iSNX-Nbmvm4"
      },
      "source": [
        "La même séparation en plusieurs colonnes pour \"bodyweight\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "eijcIgZ_wM1W"
      },
      "source": [
        "data_suicide['bodyweight'].value_counts()\n",
        "\n",
        "C = pd.get_dummies(data_suicide['bodyweight'])\n",
        "data_suicide = data_suicide.drop('bodyweight', axis=1)\n",
        "data_suicide = pd.concat([data_suicide, C], axis=1)\n",
        "data_suicide.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdjJ2Flbmx88"
      },
      "source": [
        "On convertit les \"Yes\" et \"No\" de \"virgin\" en 0 et 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Ko_srNfZ1c6z"
      },
      "source": [
        "data_suicide['virgin'] = data_suicide['virgin'].replace({'Yes':1,'No':0})\n",
        "data_suicide.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vgt7lP9om2Tf"
      },
      "source": [
        "On nettoie la colonne \"friends\" en remplaçant les valeurs supérieures à 40 (qui nous paraissent aberrantes) par la valeur 40."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "AqiHqlCQ3Q0G"
      },
      "source": [
        "data_suicide['friends'].values[data_suicide['friends'] > 40] = 40\n",
        "data_suicide['friends'] = data_suicide['friends'].astype(int)\n",
        "data_suicide.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKdPbsW0m9U4"
      },
      "source": [
        "On transforme de la colonne \"social fear\" en 0 et en 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "x2pAiurf4Beg"
      },
      "source": [
        "data_suicide['social_fear'] = data_suicide['social_fear'].map({'Yes':1,'No':0})\n",
        "data_suicide.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHEbgUtWnC0q"
      },
      "source": [
        "On transforme de la colonne \"depressed\" en 0 et en 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "YGiB3Tq4HtCu"
      },
      "source": [
        "data_suicide['depressed'] = data_suicide['depressed'].map({'Yes':1,'No':0})\n",
        "data_suicide.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7v_34DrrnFS3"
      },
      "source": [
        "La colonne \"what_help_from_others\" est difficile à traiter, mais il nous a paru pertinent de séparer les valeurs en deux colonnes : besoin d'aide et le cas contraire."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "lAk8hrqIHtFo"
      },
      "source": [
        "data_suicide['what_help_from_others'] = data_suicide['what_help_from_others'].apply(lambda x: 0 if x == 'I don\\'t want help' else 1)\n",
        "data_suicide.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5swWVzLknHMS"
      },
      "source": [
        "Transformation de la colonne \"attempt_suicide\" en 0 et en 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "9Ha2b15x6KNl"
      },
      "source": [
        "data_suicide['attempt_suicide'] = data_suicide['attempt_suicide'].map({'Yes':1, 'No':0})\n",
        "data_suicide.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcWdMRHKnJKD"
      },
      "source": [
        "On créer trois colonnes correspondant à \"student\", \"employed\" ou \"not employed\" à la place de la colonne \"employment\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "T_8BpXwZ6MZv"
      },
      "source": [
        "def parse_values(x):\n",
        "    if x == 'A student':\n",
        "       return 'Student'\n",
        "    elif x == 'Self-employed' or x == 'Military' or x == 'Employed for wages':\n",
        "       return 'Employed'\n",
        "    else:\n",
        "       return 'Not employed'\n",
        "\n",
        "data_suicide['employment'] = data_suicide['employment'].apply(parse_values)\n",
        "\n",
        "D = pd.get_dummies(data_suicide['employment'])\n",
        "data_suicide = data_suicide.drop('employment', axis=1)\n",
        "data_suicide = pd.concat([data_suicide, D], axis=1)\n",
        "data_suicide.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBTDnwW5nKqu"
      },
      "source": [
        "On créer une colonne pour chaque réponse possible dans \"edu_level\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "vfVkAoO76N5R"
      },
      "source": [
        "data_suicide['edu_level'].value_counts()\n",
        "\n",
        "E = pd.get_dummies(data_suicide['edu_level'])\n",
        "data_suicide = data_suicide.drop('edu_level', axis=1)\n",
        "data_suicide = pd.concat([data_suicide, E], axis=1)\n",
        "data_suicide.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-Z42svPnPhw"
      },
      "source": [
        "On sépare la colonne \"improve_yourself_how\" en trois : \"None\", \"go to the gym\", et \"other exercise\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "kQgClf2c6PdE"
      },
      "source": [
        "data_suicide['improve_yourself_how'].value_counts()\n",
        "\n",
        "def parse_values_improve_yourself_how(x):\n",
        "    if x == 'None':\n",
        "       return 'None'\n",
        "    elif 'Joined a gym/go to the gym' in x:\n",
        "       return 'go to the gym'\n",
        "    else:\n",
        "       return 'Other exercise'\n",
        "\n",
        "data_suicide['improve_yourself_how'] = data_suicide['improve_yourself_how'].apply(parse_values_improve_yourself_how)\n",
        "\n",
        "F = pd.get_dummies(data_suicide['improve_yourself_how'])\n",
        "data_suicide = data_suicide.drop('improve_yourself_how', axis=1)\n",
        "data_suicide = pd.concat([data_suicide, F], axis=1)\n",
        "data_suicide.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YukPnzenR66"
      },
      "source": [
        "Voici un aperçu final de notre dataset après nettoyage des données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GazUslHp80ay"
      },
      "source": [
        "data_suicide.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kREKvJIInT37"
      },
      "source": [
        "Toutes nos colonnes sont soit des entiers ou des floats."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDKuG0VgCYR6"
      },
      "source": [
        "data_suicide.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8J6gpEtqnYO_"
      },
      "source": [
        "Des informations sur le dataset final"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04-s1YV5edLy"
      },
      "source": [
        "print ('Notre dataset a {0} lignes et {1} colonnes'.format(data_suicide.shape[0],data_suicide.shape[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "1TgcVV8oefcx"
      },
      "source": [
        "data_suicide.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "xWlAlDvceffj"
      },
      "source": [
        "data_suicide.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "CPakJ5b5efjh"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.distplot(data_suicide['attempt_suicide'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdNY-ShZna8f"
      },
      "source": [
        "On crée la matrice de corrélation de notre dataset, en ne regardant évidemment que la colonne \"attempt_suicide\" "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnB56hHgefnN"
      },
      "source": [
        "data_suicide = data_suicide.rename(columns={\"High school graduate, diploma or the equivalent (for example: GED)\": \"High school graduate, diploma or the equivalent\"})\n",
        "corr = data_suicide.corr()\n",
        "corr.style.background_gradient(cmap='coolwarm')\n",
        "import seaborn as sn\n",
        "fig, ax = plt.subplots(figsize=(5,10))\n",
        "sn.heatmap(corr[['attempt_suicide']], annot=True, ax=ax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-CioUVSnevp"
      },
      "source": [
        "On trie les valeurs de la matrice de corrélation dans l'odre décroissant\n",
        "Le premier critère qui ressort de ce tri est la dépression. Ce résultat était évidemment le plus attendu et l'étude des corrélations entre les colonnes le confirment.\n",
        "En regardant tout en bas de la liste, on remarque que \"sexuallity\" et \"gender\" sont les moins corrélés aux tentatives de suicide.\n",
        "Ces critères correspondent respectivement au fait d'être hétérosexuel et d'être un homme.\n",
        "Cela signifie que ne pas être hétérosexuel et être une femme sont les deux caractéristiques les plus corrélées aux tentatives de suicide après la dépression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X2E6svfefqf"
      },
      "source": [
        "print (corr['attempt_suicide'].sort_values(ascending=False), '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSUFgQ4wUPSK"
      },
      "source": [
        "Notre problème va être résolu de manière automatique avec des algorithmes spécifiques et ne pourrait être résolu par le développement d'un logiciel classique. Il s'agit bien d'un problème de Machine Learning.\n",
        "On peut même dire qu'il s'agit ici d'un problème de Machine Learning Supervisé étant donné que nous dispons d'un jeu de données labellisées."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEKXsC7nnpKy"
      },
      "source": [
        "On sépare notre dataset entre les features utilisées pour la prédiction et la colonne attempt_suicide qui comporte l'élément à prédire."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFfj0LT_lxmb"
      },
      "source": [
        "features_columns = data_suicide.columns\n",
        "features_columns = features_columns.drop('attempt_suicide')\n",
        "features = data_suicide[features_columns]\n",
        "target_column = 'attempt_suicide'\n",
        "target = data_suicide[target_column]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dN3BqWrRnzKQ"
      },
      "source": [
        "On affiche du nombre d'occurences des individus ayant ou pas tenté de se suicider selon chaque feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "-E-4DXiFLjOm"
      },
      "source": [
        "from IPython.display import display \n",
        "for i in range(features_columns.shape[0]) :\n",
        "  mat = pd.DataFrame(data_suicide.groupby([features_columns[i],target_column]).size())\n",
        "  pd.DataFrame(data_suicide.groupby([features_columns[i],target_column]).size())\n",
        "  mat = mat.rename(columns={0:'nombre d\\'occurences'})\n",
        "  display(mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgygWPjd79LS"
      },
      "source": [
        "**Analyse en composantes principales**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eteZA1lI-C-j"
      },
      "source": [
        "On applique PCA qui afin de transformer des variables liées entre elles dites « corrélées » en nouvelles variables décorrélées les unes des autres. Ces nouvelles variables sont nommées « composantes principales », ou axes principaux. Ça nous permet de réduire le nombre de variables et de rendre l'information moins redondante en visualisant nos données."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVBJuJCckD-9"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Séparation des features\n",
        "column_names = data_suicide.columns\n",
        "column_names = column_names.drop('attempt_suicide')\n",
        "x = data_suicide.loc[:, column_names].values\n",
        "# Séparation du but\n",
        "y = data_suicide.loc[:, 'attempt_suicide'].values\n",
        "# Standarisation des features\n",
        "x = StandardScaler().fit_transform(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDpywm389zkk"
      },
      "source": [
        "**La projection en 2D PCA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zXP6tYIoN0Z"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2)\n",
        "principalComponents = pca.fit_transform(x)\n",
        "principalDf = pd.DataFrame(data = principalComponents\n",
        "             , columns = ['principal component 1', 'principal component 2'])\n",
        "finalDf = pd.concat([principalDf, data_suicide[['attempt_suicide']]], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6XqSmNC-mPs"
      },
      "source": [
        "**La visualisation de la projection 2D**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "KZeWmZzIopQ5"
      },
      "source": [
        "fig = plt.figure(figsize = (8,8))\n",
        "ax = fig.add_subplot(1,1,1) \n",
        "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
        "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
        "ax.set_title('2 component PCA', fontsize = 20)\n",
        "targets = [1, 0]\n",
        "colors = ['r', 'g', 'b']\n",
        "for target, color in zip(targets,colors):\n",
        "    indicesToKeep = finalDf['attempt_suicide'] == target\n",
        "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
        "               , finalDf.loc[indicesToKeep, 'principal component 2']\n",
        "               , c = color\n",
        "               , s = 50)\n",
        "ax.legend(targets)\n",
        "ax.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F86kTzTMvioV"
      },
      "source": [
        "# **Définition du problème en tant qu'un problème de Machine Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uZmByUFvwGO"
      },
      "source": [
        "Puisque notre problème peut être résolu de manière automatique avec des algorithmes spécifiques en se basant sur l’analyse d’un jeu de données alors on peut dire que on est amené à faire du Machine Learning. N’oublions pas que le développement d’un logiciel réalisant cette même tâche est assez complexe voire impossible. \n",
        "De manière assez spécifique, notre problème est un problème d’apprentissage automatique dit “supervisé” étant donné qu’on dispose d’un jeu de données labellisées, et on est face à un problème de classification binaire puisque on possèdera des valeurs discrètes en sortie de notre prédicteur."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWCrAQ1yzCuk"
      },
      "source": [
        "On importe des modules utilisés pour la classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKNRtbp1LjSn"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import tree\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "import matplotlib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn import metrics\n",
        "import seaborn as sns "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21deHdvOzINZ"
      },
      "source": [
        "On répartit nos features et targets pour préparer nos données d'entrainement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fgLIYKPl9k_"
      },
      "source": [
        "features_columns = data_suicide.columns\n",
        "features_columns = features_columns.drop('attempt_suicide')\n",
        "features = data_suicide[features_columns]\n",
        "target_column = 'attempt_suicide'\n",
        "target = data_suicide[target_column]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAUnuqM9zT6a"
      },
      "source": [
        "On crée les jeux d'entrainement et de test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qa9bzQltkzv"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33)\n",
        "print(\"train set shape : \", X_train.shape)\n",
        "print(\"test set shape : \",y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0u7xLxNw1fN"
      },
      "source": [
        "Nous allons tester plusieurs modèles qui tenteront chacun de résoudre ce problème de Machine Learning. Pour chaque modèle, nous évaluons le score pour déterminer lesquels semblent être à première vue les plus intéressants. Les trois modèle ayant reçu les meilleurs résultats ont de plus fait l'objet d'une étude plus approfondie pour déterminer le prédicteur à utiliser."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkiBXEJ1yetY"
      },
      "source": [
        "**Le modèle de la Regression Linéaire**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnlOd1f73Xt7"
      },
      "source": [
        "Les modèles de Logistic Regression Model, Linear Discriminant Analysis et KNeighbors présentent toutes des résulats similaires, satisfaisants sans être exceptionnels. Les test set scores est assez proche des training set scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiYQBrPcIY2M"
      },
      "source": [
        "clf_lr = LogisticRegression(solver='lbfgs')\n",
        "clf_lr.fit(X_train, y_train) \n",
        "#print(\"intercept: {}\".format(clf_lr.intercept_))\n",
        "#print(\"weights:   {}\".format(clf_lr.coef_))\n",
        "\n",
        "train_score = clf_lr.score(X_train,y_train)\n",
        "test_score = clf_lr.score(X_test,y_test)\n",
        "\n",
        "print(\"Training set score: {:.2f} \".format(train_score))\n",
        "print(\"Test set score: {:.2f} \".format(test_score))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEwCyT-MpWQz"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Séparation des features\n",
        "column_names = data_suicide.columns\n",
        "column_names = column_names.drop('attempt_suicide')\n",
        "x = data_suicide.loc[:, column_names].values\n",
        "# Séparation du but\n",
        "y = data_suicide.loc[:, 'attempt_suicide'].values\n",
        "# Standarisation des features\n",
        "x = StandardScaler().fit_transform(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSfeAB3M2yIo"
      },
      "source": [
        "**Le modèle Analyse Discriminante Linéaire**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yl-1s50t4G7N"
      },
      "source": [
        "Le LDA Classifier n'a pas été aussi performant. Son training set score est très élevé mais les résultats sont beaucoup moins bons par rapport aux autres modèles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_msdrkXEq5o"
      },
      "source": [
        "lda = LinearDiscriminantAnalysis()\n",
        "lda.fit(X_train, y_train)\n",
        "print(\"Training set score: {:.2f} \".format(round(lda.score(X_train,y_train), 4)))\n",
        "print(\"Test set score: {:.2f} \".format(round(lda.score(X_test,y_test), 4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lC3KZX7d2jUi"
      },
      "source": [
        "**Le modèle KNeighbors**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82NWIzQI3OeO"
      },
      "source": [
        "Le KNeigbors Classifier n'a pas été aussi performant également. Les résultats sur le test set ne sont pas les meilleurs à obtenir."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnNh_ZMLEwLq"
      },
      "source": [
        "neigh = KNeighborsClassifier(n_neighbors=7)\n",
        "neigh.fit(X_train, y_train)\n",
        "print(\"Training set score: {:.2f} \".format(round(neigh.score(X_train,y_train), 4)))\n",
        "print(\"Test set score: {:.2f} \".format(round(neigh.score(X_test,y_test), 4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WynaVGNV2eQs"
      },
      "source": [
        "**Le modèle Decision Tree**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPk0J7Nu3LT1"
      },
      "source": [
        "Le Decision Tree Classifier n'a pas été aussi performant. Son training set score est très élevé mais les résultats sont beaucoup moins bons sur le test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cH6WiymA9DRi"
      },
      "source": [
        "my_tree = tree.DecisionTreeClassifier()\n",
        "my_tree.fit(X_train, y_train)\n",
        "\n",
        "train_score = my_tree.score(X_train,y_train)\n",
        "test_score = my_tree.score(X_test,y_test)\n",
        "\n",
        "print(\"Training set score: {:.2f} \".format(train_score))\n",
        "print(\"Test set score: {:.2f} \".format(test_score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBo1VV752YjY"
      },
      "source": [
        "**Le modèle GaussianNB**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kj8FQmVg3I_v"
      },
      "source": [
        "Le Bayesien naïf a été le seul modèle réellement mauvais parmis ceux que nous avons testés. Ces résultats sont de 0.25 pour les deux sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQSKuZVFSDeF"
      },
      "source": [
        "gaussian = GaussianNB()\n",
        "gaussian.fit(X_train, y_train)\n",
        "\n",
        "train_score = gaussian.score(X_train,y_train)\n",
        "test_score = gaussian.score(X_test,y_test)\n",
        "\n",
        "print(\"Training set score: {:.2f} \".format(train_score))\n",
        "print(\"Test set score: {:.2f} \".format(test_score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDyMLtT62GKd"
      },
      "source": [
        "**Le modèle SVC**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48wBAXl42Jvw"
      },
      "source": [
        "Pour le modèle SVC qui nous a paru intéressant à étudier de plus près, nous avons testé différents hyper paramètres pour déterminer un prédicteur optimal avec cette méthode. Ici les résultats sont identiques avec \"precision\" et \"recall\". On obtient au mieux un test set score de 0,82."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "xk7SV7QHDDqt",
        "outputId": "0285e103-3393-40fe-eb93-e0a24aeaebd7"
      },
      "source": [
        "svc = svm.SVC(kernel='linear', C=1)\n",
        "svc.fit(X_train, y_train)\n",
        "\n",
        "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
        "                     'C': [1, 10, 100, 1000]},\n",
        "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
        "\n",
        "scores = ['precision', 'recall']\n",
        "\n",
        "for score in scores:\n",
        "    print(\"# Réglage des hyper-parameters pour %s\" % score)\n",
        "    print()\n",
        "\n",
        "    clf = GridSearchCV(\n",
        "        SVC(), tuned_parameters, scoring='%s_macro' % score\n",
        "    )\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    print(\"Les meilleurs paramètres trouvés : \")\n",
        "    print()\n",
        "    print(clf.best_params_)\n",
        "    print()\n",
        "    print(\"Scores du grid :\")\n",
        "    print()\n",
        "    means = clf.cv_results_['mean_test_score']\n",
        "    stds = clf.cv_results_['std_test_score']\n",
        "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "        print(\"%0.3f (+/-%0.03f) pour %r\"\n",
        "              % (mean, std * 2, params))\n",
        "    print()\n",
        "\n",
        "    print(\"Rapport détaillé :\")\n",
        "    y_true, y_pred = y_test, clf.predict(X_test)\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    print()\n",
        "\n",
        "print(\"Test set score: {:.2f} \".format(round(svc.score(X_test,y_test), 4)))\n",
        "print(\"Training set score: {:.2f} \".format(round(svc.score(X_train,y_train), 4)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Réglage des hyper-parameters pour precision\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "296Et-EL15rl"
      },
      "source": [
        "**Le modèle RandomForest**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR1n8HZ21960"
      },
      "source": [
        "Nous avons également étudié de plus près de modèle de Random Forest. Ici, \"recall\" s'est montré légèrement plus performant. Il nous permet alors d'atteindre un test set score de 0,84."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKDxQaLyLhIw",
        "outputId": "92bf029d-77a8-4c2c-f11e-09b327f0eb32"
      },
      "source": [
        "rf = RandomForestClassifier(max_depth=10,min_samples_split=2)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "param_grid = {'max_depth': [3, 5, 10],\n",
        "             'min_samples_split': [2, 5, 10]}\n",
        "base_estimator = RandomForestClassifier()\n",
        "\n",
        "scores = ['precision', 'recall']\n",
        "\n",
        "for score in scores:\n",
        "    print(\"# Réglage des hyper-parameters pour %s\" % score)\n",
        "    print()\n",
        "\n",
        "    clf = GridSearchCV(\n",
        "        base_estimator, param_grid, scoring='%s_macro' % score\n",
        "    )\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    print(\"Les meilleurs paramètres trouvés : \")\n",
        "    print()\n",
        "    print(clf.best_params_)\n",
        "    print()\n",
        "    print(\"Scores du grid :\")\n",
        "    print()\n",
        "    means = clf.cv_results_['mean_test_score']\n",
        "    stds = clf.cv_results_['std_test_score']\n",
        "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "        print(\"%0.3f (+/-%0.03f) pour %r\"\n",
        "              % (mean, std * 2, params))\n",
        "    print()\n",
        "\n",
        "    print(\"Rapport détaillé :\")\n",
        "    y_true, y_pred = y_test, clf.predict(X_test)\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    print()\n",
        "\n",
        "print(\"Test set score: {:.2f} \".format(round(rf.score(X_test,y_test), 4)))\n",
        "print(\"Training set score: {:.2f} \".format(round(rf.score(X_train,y_train), 4)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Réglage des hyper-parameters pour precision\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Les meilleurs paramètres trouvés : \n",
            "\n",
            "{'max_depth': 10, 'min_samples_split': 2}\n",
            "\n",
            "Scores du grid :\n",
            "\n",
            "0.407 (+/-0.007) pour {'max_depth': 3, 'min_samples_split': 2}\n",
            "0.407 (+/-0.007) pour {'max_depth': 3, 'min_samples_split': 5}\n",
            "0.407 (+/-0.007) pour {'max_depth': 3, 'min_samples_split': 10}\n",
            "0.407 (+/-0.007) pour {'max_depth': 5, 'min_samples_split': 2}\n",
            "0.407 (+/-0.007) pour {'max_depth': 5, 'min_samples_split': 5}\n",
            "0.407 (+/-0.007) pour {'max_depth': 5, 'min_samples_split': 10}\n",
            "0.559 (+/-0.405) pour {'max_depth': 10, 'min_samples_split': 2}\n",
            "0.508 (+/-0.402) pour {'max_depth': 10, 'min_samples_split': 5}\n",
            "0.508 (+/-0.401) pour {'max_depth': 10, 'min_samples_split': 10}\n",
            "\n",
            "Rapport détaillé :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.99      0.91       129\n",
            "           1       0.75      0.12      0.20        26\n",
            "\n",
            "    accuracy                           0.85       155\n",
            "   macro avg       0.80      0.55      0.56       155\n",
            "weighted avg       0.83      0.85      0.79       155\n",
            "\n",
            "\n",
            "# Réglage des hyper-parameters pour recall\n",
            "\n",
            "Les meilleurs paramètres trouvés : \n",
            "\n",
            "{'max_depth': 10, 'min_samples_split': 10}\n",
            "\n",
            "Scores du grid :\n",
            "\n",
            "0.500 (+/-0.000) pour {'max_depth': 3, 'min_samples_split': 2}\n",
            "0.500 (+/-0.000) pour {'max_depth': 3, 'min_samples_split': 5}\n",
            "0.500 (+/-0.000) pour {'max_depth': 3, 'min_samples_split': 10}\n",
            "0.500 (+/-0.000) pour {'max_depth': 5, 'min_samples_split': 2}\n",
            "0.500 (+/-0.000) pour {'max_depth': 5, 'min_samples_split': 5}\n",
            "0.500 (+/-0.000) pour {'max_depth': 5, 'min_samples_split': 10}\n",
            "0.496 (+/-0.010) pour {'max_depth': 10, 'min_samples_split': 2}\n",
            "0.498 (+/-0.008) pour {'max_depth': 10, 'min_samples_split': 5}\n",
            "0.506 (+/-0.036) pour {'max_depth': 10, 'min_samples_split': 10}\n",
            "\n",
            "Rapport détaillé :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.99      0.91       129\n",
            "           1       0.50      0.04      0.07        26\n",
            "\n",
            "    accuracy                           0.83       155\n",
            "   macro avg       0.67      0.52      0.49       155\n",
            "weighted avg       0.78      0.83      0.77       155\n",
            "\n",
            "\n",
            "Test set score: 0.85 \n",
            "Training set score: 0.96 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ap2IsVwKx7pD"
      },
      "source": [
        "**Le modèle Perceptron**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrE8Mguh1yzM"
      },
      "source": [
        "Le modèle du Perceptron a montré de nombreuses instabilité avec des résultats très variables. Nous avons donc décidé d'abandonner le modèle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iNfXoPsCU5al",
        "outputId": "ebf60c73-f5e6-4338-be34-91e375c0b2b9"
      },
      "source": [
        "p = Perceptron(tol=1e-3, random_state=0)\n",
        "p.fit(X_train, y_train)\n",
        "print(\"Test set score: {:.2f} \".format(round(p.score(X_test,y_test), 4)))\n",
        "print(\"Training set score: {:.2f} \".format(round(p.score(X_train,y_train), 4)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set score: 0.85 \n",
            "Training set score: 0.82 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDM74gpN1hwW"
      },
      "source": [
        "**Le modèle MLP**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSkj4ElG1saZ"
      },
      "source": [
        "Nous avons également étudié le MLPClassifier, et cette fois si \"precision\" semblait être plus pertinent. Nous avons même réussi à atteindre un test set score de 0,98, plus élevé que sur le training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iDzKAdifcLS",
        "outputId": "489f0548-6f38-49dc-bd01-6ebe339424b5"
      },
      "source": [
        "mlp = MLPClassifier(alpha=0.05, hidden_layer_sizes=(50, 50, 50), solver='adam')\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "param_grid = {'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
        "    'solver': ['sgd', 'adam'],\n",
        "    'alpha': [0.0001, 0.05],}\n",
        "base_estimator = MLPClassifier()\n",
        "\n",
        "scores = ['precision', 'recall']\n",
        "\n",
        "for score in scores:\n",
        "    print(\"# Réglage des hyper-parameters pour %s\" % score)\n",
        "    print()\n",
        "\n",
        "    clf = GridSearchCV(\n",
        "        base_estimator, param_grid, scoring='%s_macro' % score\n",
        "    )\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    print(\"Les meilleurs paramètres trouvés : \")\n",
        "    print()\n",
        "    print(clf.best_params_)\n",
        "    print()\n",
        "    print(\"Scores du grid :\")\n",
        "    print()\n",
        "    means = clf.cv_results_['mean_test_score']\n",
        "    stds = clf.cv_results_['std_test_score']\n",
        "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "        print(\"%0.3f (+/-%0.03f) pour %r\"\n",
        "              % (mean, std * 2, params))\n",
        "    print()\n",
        "\n",
        "    print(\"Rapport détaillé :\")\n",
        "    y_true, y_pred = y_test, clf.predict(X_test)\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    print()\n",
        "\n",
        "print(\"Test set score: {:.2f} \".format(round(mlp.score(X_train,y_train), 4)))\n",
        "print(\"Training set score: {:.2f} \".format(round(mlp.score(X_test,y_test), 4)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "# Réglage des hyper-parameters pour precision\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Les meilleurs paramètres trouvés : \n",
            "\n",
            "{'alpha': 0.05, 'hidden_layer_sizes': (100,), 'solver': 'adam'}\n",
            "\n",
            "Scores du grid :\n",
            "\n",
            "0.407 (+/-0.007) pour {'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'solver': 'sgd'}\n",
            "0.660 (+/-0.285) pour {'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'solver': 'adam'}\n",
            "0.407 (+/-0.007) pour {'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'solver': 'sgd'}\n",
            "0.653 (+/-0.160) pour {'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'solver': 'adam'}\n",
            "0.407 (+/-0.007) pour {'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'solver': 'sgd'}\n",
            "0.581 (+/-0.381) pour {'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'solver': 'adam'}\n",
            "0.407 (+/-0.007) pour {'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'solver': 'sgd'}\n",
            "0.634 (+/-0.207) pour {'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'solver': 'adam'}\n",
            "0.407 (+/-0.007) pour {'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'solver': 'sgd'}\n",
            "0.593 (+/-0.212) pour {'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'solver': 'adam'}\n",
            "0.407 (+/-0.007) pour {'alpha': 0.05, 'hidden_layer_sizes': (100,), 'solver': 'sgd'}\n",
            "0.689 (+/-0.264) pour {'alpha': 0.05, 'hidden_layer_sizes': (100,), 'solver': 'adam'}\n",
            "\n",
            "Rapport détaillé :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.93      0.90       129\n",
            "           1       0.44      0.27      0.33        26\n",
            "\n",
            "    accuracy                           0.82       155\n",
            "   macro avg       0.65      0.60      0.61       155\n",
            "weighted avg       0.79      0.82      0.80       155\n",
            "\n",
            "\n",
            "# Réglage des hyper-parameters pour recall\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Les meilleurs paramètres trouvés : \n",
            "\n",
            "{'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'solver': 'adam'}\n",
            "\n",
            "Scores du grid :\n",
            "\n",
            "0.500 (+/-0.000) pour {'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'solver': 'sgd'}\n",
            "0.550 (+/-0.073) pour {'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'solver': 'adam'}\n",
            "0.500 (+/-0.000) pour {'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'solver': 'sgd'}\n",
            "0.545 (+/-0.079) pour {'alpha': 0.0001, 'hidden_layer_sizes': (50, 100, 50), 'solver': 'adam'}\n",
            "0.500 (+/-0.000) pour {'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'solver': 'sgd'}\n",
            "0.563 (+/-0.057) pour {'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'solver': 'adam'}\n",
            "0.500 (+/-0.000) pour {'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'solver': 'sgd'}\n",
            "0.567 (+/-0.052) pour {'alpha': 0.05, 'hidden_layer_sizes': (50, 50, 50), 'solver': 'adam'}\n",
            "0.500 (+/-0.000) pour {'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'solver': 'sgd'}\n",
            "0.556 (+/-0.128) pour {'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'solver': 'adam'}\n",
            "0.500 (+/-0.000) pour {'alpha': 0.05, 'hidden_layer_sizes': (100,), 'solver': 'sgd'}\n",
            "0.555 (+/-0.051) pour {'alpha': 0.05, 'hidden_layer_sizes': (100,), 'solver': 'adam'}\n",
            "\n",
            "Rapport détaillé :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86       129\n",
            "           1       0.32      0.31      0.31        26\n",
            "\n",
            "    accuracy                           0.77       155\n",
            "   macro avg       0.59      0.59      0.59       155\n",
            "weighted avg       0.77      0.77      0.77       155\n",
            "\n",
            "\n",
            "Test set score: 0.97 \n",
            "Training set score: 0.81 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0-TWKSq1R-F"
      },
      "source": [
        "Nous avons effectué une comparaisons de tous les modèles testés avec une validation croisée. Nous avons pris le résultat médian pour chacun des modèles pour observer lesquels sont les plus performants de manière stable. Cependant, à quelques rares exceptions près, tous les modèles donnent de résultats similaires avec un score médian compris entre 0,78 et 0,83."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGw9CO_P_ccp",
        "outputId": "183d0094-7930-46a7-9045-566615598756"
      },
      "source": [
        "\n",
        "seed = 7\n",
        "\n",
        "models = []\n",
        "models.append(('LR', LogisticRegression()))\n",
        "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
        "models.append(('KNN', KNeighborsClassifier()))\n",
        "models.append(('DTC', DecisionTreeClassifier()))\n",
        "models.append(('GNB', GaussianNB()))\n",
        "models.append(('SVC', SVC()))\n",
        "models.append(('RF', RandomForestClassifier()))\n",
        "models.append(('P', Perceptron()))\n",
        "models.append(('MLP', MLPClassifier()))\n",
        "\n",
        "results = []\n",
        "medians = []\n",
        "scoring = 'accuracy'\n",
        "for name, model in models:\n",
        "\tkfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
        "\tcv_results = model_selection.cross_val_score(model, features, target, cv=kfold, scoring=scoring)\n",
        "\tresults.append(cv_results)\n",
        " \n",
        "for i in range(len(results)):\n",
        "  medians.append(np.median(results[i]))\n",
        "\n",
        "liste = ['LR', 'LDA', 'KNN', 'DTC', 'GNB', 'SVC', 'RF', 'P', 'MLP']\n",
        "\n",
        "i = 0\n",
        "for methode in liste:\n",
        "  print(\"median de la methode \", methode, \"est : \", medians[i])\n",
        "  i = i + 1 \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWHk864o506y"
      },
      "source": [
        "# **Les prédicteurs**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CY2aVus65KCn"
      },
      "source": [
        "Pour le choix des prédicteurs qu'on va livrer en fin de cette étude, on cite les 3 meilleurs modèles pour ce jeu de données :\n",
        "*   SVC\n",
        "*   RandomForest\n",
        "*   MLP\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cse5KsyA5_nP"
      },
      "source": [
        "On a choisi la matrice de confusion comme repère pour nous guider quel prédicteur est meilleur par rapport aux autres.\n",
        "Cette matrice mesure la qualité d'un système de classification. \n",
        "Chaque ligne correspond à une classe réelle, chaque colonne correspond à une classe estimée."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGotPhiF6yx1"
      },
      "source": [
        "Comme on le voit dans une matrice de confusion, chaque composant représente un scénario différent et \n",
        "peut être interprété différemment pour dériver des mesures autres que la précision. \n",
        "Les plus courants sont la précision , le rappel, le score F1 et le support."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo6y5xNH63N9"
      },
      "source": [
        "La précision est utilisée pour mesurer les modèles positifs qui sont correctement prédits à partir du total des modèles prédits dans une classe positive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k02qmJGS7C0x"
      },
      "source": [
        "Le rappel est utilisée pour mesurer la fraction des positifs motifs qui sont correctement classés."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G57WGIHO8Kuu"
      },
      "source": [
        "Score F1 cette métrique représente la moyenne harmonique entre les valeurs de rappel et de précision , parfois également appelée mesure F."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apQGcNoK8QAT"
      },
      "source": [
        "Le support est le nombre d'échantillons de la vraie réponse qui se trouvent dans cette classe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA0YdXOJ9gY9"
      },
      "source": [
        "L'erreur absolue moyenne (EAM ou MAE pour Mean Absolute Error) : moyenne arithmétique des valeurs absolues des écarts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oT4PoCZ9h2A"
      },
      "source": [
        "Le carré moyen des erreurs (MSE pour Mean Square Error ou MCE pour moyenne des carrés des erreurs) : c’est la moyenne arithmétique des carrés des écarts entre prévisions du modèle et observations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5dZPypx9lKJ"
      },
      "source": [
        "L’erreur quadratique moyenne (RMSE) : racine carrée du précédent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYf7FTwl-tYb"
      },
      "source": [
        "Les poids du class_weight paramètre sont utilisés pour entraîner le classificateur . Ils ne sont utilisés dans le calcul d'aucune des métriques qu'on utilise : avec des poids de classe différents, les nombres seront différents simplement parce que le classificateur est différent.\n",
        "\n",
        "Fondamentalement, dans chaque classificateur scikit-learn, les poids de classe sont utilisés pour indiquer à notre modèle l'importance d'une classe. Cela signifie que pendant la formation, le classificateur fera des efforts supplémentaires pour classer correctement les classes avec des poids élevés."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfTvkTjg-wNG"
      },
      "source": [
        "Habituellement, lorsque la distribution des classes est déséquilibrée, la précision est considérée comme un mauvais choix car elle donne des scores élevés aux modèles qui ne font que prédire la classe la plus fréquente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6h9WkSX8VWm"
      },
      "source": [
        "**Le prédicteur SVC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pyhV9obEFpOv",
        "outputId": "67628e12-3ed6-4b59-81fe-1622cc337f19"
      },
      "source": [
        "def predictor_SVC(xx,yy):\n",
        "  y_pred = svc.predict(xx)\n",
        "  cp=pd.DataFrame({'Actual': yy, 'Predicted': y_pred})\n",
        "  print(cp) \n",
        "  print(confusion_matrix(yy,y_pred))\n",
        "  print(classification_report(yy,y_pred))\n",
        "  print(accuracy_score(yy, y_pred))\n",
        "  print('Mean Absolute Error:', metrics.mean_absolute_error(yy, y_pred))\n",
        "  print('Mean Squared Error:', metrics.mean_squared_error(yy, y_pred))\n",
        "  print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(yy, y_pred)))\n",
        "\n",
        "  plt.figure(figsize=(5, 7))\n",
        "\n",
        "\n",
        "  ax = sns.distplot(yy, hist=False, color=\"r\", label=\"Actual Value\")\n",
        "  sns.distplot(y_pred, hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax)\n",
        "\n",
        "\n",
        "  plt.title('Actual vs Fitted Values for Suicide Attempts')\n",
        "\n",
        "\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "predictor_SVC(X_test,y_test)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "     Actual  Predicted\n",
            "366       0          0\n",
            "324       0          0\n",
            "126       0          0\n",
            "208       0          0\n",
            "446       0          0\n",
            "..      ...        ...\n",
            "18        1          0\n",
            "286       0          0\n",
            "216       0          0\n",
            "417       0          0\n",
            "59        0          0\n",
            "\n",
            "[155 rows x 2 columns]\n",
            "[[128   1]\n",
            " [ 23   3]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.99      0.91       129\n",
            "           1       0.75      0.12      0.20        26\n",
            "\n",
            "    accuracy                           0.85       155\n",
            "   macro avg       0.80      0.55      0.56       155\n",
            "weighted avg       0.83      0.85      0.79       155\n",
            "\n",
            "0.8451612903225807\n",
            "Mean Absolute Error: 0.15483870967741936\n",
            "Mean Squared Error: 0.15483870967741936\n",
            "Root Mean Squared Error: 0.39349550147037177\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_yK9dZ98bVA"
      },
      "source": [
        "**Le prédicteur RandomForest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVvyfX5tt9FT"
      },
      "source": [
        "def predictor_RF(xx,yy):\n",
        "  y_pred = rf.predict(xx)\n",
        "  cp=pd.DataFrame({'Actual': yy, 'Predicted': y_pred})\n",
        "  print(cp) \n",
        "  print(confusion_matrix(yy,y_pred))\n",
        "  print(classification_report(yy,y_pred))\n",
        "  print(accuracy_score(yy, y_pred))\n",
        "  print('Mean Absolute Error:', metrics.mean_absolute_error(yy, y_pred))\n",
        "  print('Mean Squared Error:', metrics.mean_squared_error(yy, y_pred))\n",
        "  print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(yy, y_pred)))\n",
        "\n",
        "  plt.figure(figsize=(5, 7))\n",
        "\n",
        "\n",
        "  ax = sns.distplot(yy, hist=False, color=\"r\", label=\"Actual Value\")\n",
        "  sns.distplot(y_pred, hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax)\n",
        "\n",
        "\n",
        "  plt.title('Actual vs Fitted Values for Suicide Attempts')\n",
        "\n",
        "\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "predictor_RF(X_test,y_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IJD5frX8fjV"
      },
      "source": [
        "**Le prédicteur MLP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffk1iUNKifeb"
      },
      "source": [
        "def predictor_MLP(xx,yy):\n",
        "  y_pred = mlp.predict(xx)\n",
        "  cp=pd.DataFrame({'Actual': yy, 'Predicted': y_pred})\n",
        "  print(cp) \n",
        "  print(confusion_matrix(yy,y_pred))\n",
        "  print(classification_report(yy,y_pred))\n",
        "  print(accuracy_score(yy, y_pred))\n",
        "  print('Mean Absolute Error:', metrics.mean_absolute_error(yy, y_pred))\n",
        "  print('Mean Squared Error:', metrics.mean_squared_error(yy, y_pred))\n",
        "  print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(yy, y_pred)))\n",
        "\n",
        "  plt.figure(figsize=(5, 7))\n",
        "\n",
        "\n",
        "  ax = sns.distplot(yy, hist=False, color=\"r\", label=\"Actual Value\")\n",
        "  sns.distplot(y_pred, hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax)\n",
        "\n",
        "\n",
        "  plt.title('Actual vs Fitted Values for Suicide Attempts')\n",
        "\n",
        "\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "predictor_MLP(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELLrRHw__CNC"
      },
      "source": [
        "Enfin pour les trois méthodes que nous avons retenues, nous avons calculé les Mean Absolute Errors et Mean Squared Errors et affiché les densités prédites pour les comparer aux densités réelles sur le test set.\n",
        "Les résultats varient légèrement d'une exécution à une autre, mais on remarque que les erreurs sont assez similaires pour chaque modèle. Cependant, la courbe de prédiction pour le prédicteur MLP se rapproche nettement plus de la courbe réelle, et nous recommandons donc l'utilisation de ce prédicteur pour la résolution de ce problème."
      ]
    }
  ]
}